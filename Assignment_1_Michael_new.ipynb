{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2020 Semester 1\n",
    "\n",
    "## Assignment 1: Naive Bayes Classifiers\n",
    "\n",
    "###### Submission deadline: 7 pm, Monday 20 Apr 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student Name(s):**    `Alec Yu, Michael Jaworski`\n",
    "\n",
    "**Student ID(s):**     `993433, 833751`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This iPython notebook is a template which you will use for your Assignment 1 submission.\n",
    "\n",
    "Marking will be applied on the four functions that are defined in this notebook, and to your responses to the questions at the end of this notebook (Submitted in a separate PDF file).\n",
    "\n",
    "**NOTE: YOU SHOULD ADD YOUR RESULTS, DIAGRAMS AND IMAGES FROM YOUR OBSERVATIONS IN THIS FILE TO YOUR REPORT (the PDF file).**\n",
    "\n",
    "You may change the prototypes of these functions, and you may write other functions, according to your requirements. We would appreciate it if the required functions were prominent/easy to find.\n",
    "\n",
    "**Adding proper comments to your code is MANDATORY. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# count attribute values\n",
    "from collections import Counter\n",
    "from math import sqrt, e, pi, log\n",
    "from random import sample\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filenames(location: str):\n",
    "    \n",
    "    # returns filenames from datasets folder location\n",
    "    \n",
    "    files = os.listdir(location)\n",
    "    \n",
    "    return [filename.replace(\".data\", \"\") for filename in files if \".data\" in filename]\n",
    "    \n",
    "\n",
    "def read_data(filename: str):  \n",
    "    \n",
    "    # reads the filename.data data file and the filename.h header file and return a dataframe \n",
    "    \n",
    "    df = pd.read_csv(f\"datasets/{filename}.data\", header=None)\n",
    "    header = open(f\"datasets/{filename}.h\", \"r\").read().split(\",\")\n",
    "    df.columns = header\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_dtypes(filename: str):\n",
    "    \n",
    "    dtypes = {}\n",
    "    \n",
    "    rows = open(f\"datasets/{filename}.dtypes.txt\").read().split(\"\\n\")\n",
    "    \n",
    "    for row in rows:\n",
    "        attribute = row.split(\": \")[0]\n",
    "        dtype = row.split(\": \")[1]\n",
    "        dtypes[attribute] = dtype\n",
    "    \n",
    "    return dtypes\n",
    "\n",
    "def replace_all(df, d):\n",
    "    \n",
    "    # replace multiple strings (i.e. '?' and 'unknown' with np.nan)\n",
    "    \n",
    "    for k, v in d.items():\n",
    "        df = df.replace(k, v)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # find nan encoding i.e. '?' or 'unknown' \n",
    "\n",
    "# # get filenames\n",
    "# filenames = get_filenames(\"datasets\")\n",
    "\n",
    "# attribute_values_list = []\n",
    "\n",
    "# for filename in filenames:\n",
    "    \n",
    "#     df = read_data(filename)\n",
    "    \n",
    "#     for column in df.columns[:-1]:\n",
    "#         attribute_values = df[column].tolist()\n",
    "#         attribute_values_list.append(attribute_values)\n",
    "        \n",
    "# # sort attribute values by frequency\n",
    "\n",
    "# attribute_values = [value for attribute_values in attribute_values_list for value in attribute_values]\n",
    "# attribute_value_counter = Counter(attribute_values)\n",
    "# attribute_value_counter = {k:v for k, v in sorted(attribute_value_counter.items(), key = lambda item: item[1], reverse = True)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hence, 'unknown' and '?' represent missing values... replace missing values with np.nan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should prepare the data by reading it from a file and converting it into a useful format for training and testing\n",
    "\n",
    "def preprocess(df, filename):\n",
    "    \n",
    "    # replace missing values with np.nan\n",
    "    \n",
    "    replacements = {\"unknown\": np.nan, \"?\": np.nan}  \n",
    "    df = replace_all(df, replacements)\n",
    "    \n",
    "    # drop 'na' columns\n",
    "    df = df.dropna(axis = 'columns')\n",
    "    \n",
    "    # rearrange class to [-1] position\n",
    "    CLASS = df.pop(\"CLASS\").astype(\"category\")\n",
    "    df[\"CLASS\"] = CLASS\n",
    "    \n",
    "    # correct dtypes\n",
    "    \n",
    "    nominal_files = [\"breast-cancer-wisconsin\", \"mushroom\", \"lymphography\"]\n",
    "    numeric_files = [\"wdbc\", \"wine\"]\n",
    "    ordinal_files = [\"car\", \"nursery\", \"somerville\"]\n",
    "    mixed_files = [\"adult\", \"bank\", \"university\"]\n",
    "    \n",
    "    if (filename in nominal_files):\n",
    "        datatype = \"nominal\"\n",
    "        for column in df.columns[:-1]:\n",
    "            df[column] = df[column].astype(\"category\")\n",
    "            \n",
    "    elif (filename in ordinal_files):\n",
    "        datatype = \"ordinal\"\n",
    "        for column in df.columns[:-1]:\n",
    "            df[column] = df[column].astype(\"category\")\n",
    "        \n",
    "    elif (filename in numeric_files):\n",
    "        datatype = \"numeric\"\n",
    "        for column in df.columns[:-1]:\n",
    "            df[column] = pd.to_numeric(df[column])\n",
    "        \n",
    "    elif (filename in mixed_files):\n",
    "        datatype = \"mixed\"\n",
    "        dtypes = get_dtypes(filename)\n",
    "        for column in df.columns[:-1]:\n",
    "            try:\n",
    "                dtype = dtypes[column]\n",
    "                if dtype == \"categoric\":\n",
    "                    df[column] = df[column].astype(\"category\")\n",
    "                if dtype == \"numeric\":\n",
    "                    df[column] = pd.to_numeric(df[column])\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>university-name</th>\n",
       "      <th>state</th>\n",
       "      <th>control</th>\n",
       "      <th>number-of-students</th>\n",
       "      <th>male:female-ratio</th>\n",
       "      <th>student:faculty-ratio</th>\n",
       "      <th>sat-veral</th>\n",
       "      <th>sat-math</th>\n",
       "      <th>expenses</th>\n",
       "      <th>percent-financial-aid</th>\n",
       "      <th>number-of-applicants</th>\n",
       "      <th>percent-admittance</th>\n",
       "      <th>percent-enrolled</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>social</th>\n",
       "      <th>quality-of-life</th>\n",
       "      <th>academic-emphasis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adelphi</td>\n",
       "      <td>newyork</td>\n",
       "      <td>private</td>\n",
       "      <td>5-10</td>\n",
       "      <td>0.30</td>\n",
       "      <td>15.0</td>\n",
       "      <td>500</td>\n",
       "      <td>475</td>\n",
       "      <td>7-10</td>\n",
       "      <td>60</td>\n",
       "      <td>4-7</td>\n",
       "      <td>70</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arizona-state</td>\n",
       "      <td>arizona</td>\n",
       "      <td>state</td>\n",
       "      <td>20+</td>\n",
       "      <td>0.50</td>\n",
       "      <td>20.0</td>\n",
       "      <td>450</td>\n",
       "      <td>500</td>\n",
       "      <td>4-7</td>\n",
       "      <td>50</td>\n",
       "      <td>17+</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>fine-arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boston-college</td>\n",
       "      <td>massachusetts</td>\n",
       "      <td>private:roman-catholic</td>\n",
       "      <td>5-10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>20.0</td>\n",
       "      <td>500</td>\n",
       "      <td>550</td>\n",
       "      <td>10+</td>\n",
       "      <td>60</td>\n",
       "      <td>10-13</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boston-university</td>\n",
       "      <td>massachusetts</td>\n",
       "      <td>private</td>\n",
       "      <td>10-15</td>\n",
       "      <td>0.45</td>\n",
       "      <td>12.0</td>\n",
       "      <td>550</td>\n",
       "      <td>575</td>\n",
       "      <td>10+</td>\n",
       "      <td>60</td>\n",
       "      <td>13-17</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>liberal-arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brown</td>\n",
       "      <td>rhodeisland</td>\n",
       "      <td>private</td>\n",
       "      <td>5-</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.0</td>\n",
       "      <td>625</td>\n",
       "      <td>650</td>\n",
       "      <td>10+</td>\n",
       "      <td>40</td>\n",
       "      <td>10-13</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>arts:sciences</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     university-name          state                 control  \\\n",
       "0            adelphi        newyork                 private   \n",
       "1      arizona-state        arizona                   state   \n",
       "2     boston-college  massachusetts  private:roman-catholic   \n",
       "3  boston-university  massachusetts                 private   \n",
       "4              brown    rhodeisland                 private   \n",
       "\n",
       "  number-of-students  male:female-ratio  student:faculty-ratio  sat-veral  \\\n",
       "0               5-10               0.30                   15.0        500   \n",
       "1                20+               0.50                   20.0        450   \n",
       "2               5-10               0.40                   20.0        500   \n",
       "3              10-15               0.45                   12.0        550   \n",
       "4                 5-               0.50                   11.0        625   \n",
       "\n",
       "   sat-math expenses  percent-financial-aid number-of-applicants  \\\n",
       "0       475     7-10                     60                  4-7   \n",
       "1       500      4-7                     50                  17+   \n",
       "2       550      10+                     60                10-13   \n",
       "3       575      10+                     60                13-17   \n",
       "4       650      10+                     40                10-13   \n",
       "\n",
       "   percent-admittance  percent-enrolled  CLASS  social  quality-of-life  \\\n",
       "0                  70                40      2       2                2   \n",
       "1                  80                60      3       4                5   \n",
       "2                  50                40      4       5                3   \n",
       "3                  60                40      4       4                3   \n",
       "4                  20                50      5       4                5   \n",
       "\n",
       "  academic-emphasis  \n",
       "0           biology  \n",
       "1         fine-arts  \n",
       "2           english  \n",
       "3      liberal-arts  \n",
       "4     arts:sciences  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"university\"\n",
    "df = read_data(filename)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k_means discretization function.\n",
    "# optimise_k and get_wss function used to determine optimal k value.\n",
    "\n",
    "def k_means(values, k, old_centroids = None):\n",
    "\n",
    "    # 1. Select k points at random to act as seed centroids\n",
    "    # 2. Assign each instance to the cluster with nearest\n",
    "    # centroid\n",
    "    # 3. Recompute centroids of the clusters using current\n",
    "    # assignment. Centroid = centre or mean point of cluster\n",
    "    # 4. Repeat step 2 until the assignment of instances to\n",
    "    # clusters is stable\n",
    "    \n",
    "    if old_centroids == None:\n",
    "        centroids = sample(list(set(values)), k)\n",
    "    else:\n",
    "        centroids = old_centroids    \n",
    "        \n",
    "    clusters = [None for val in range(len(values))]\n",
    "\n",
    "    for i in range(len(values)):\n",
    "        value = values[i]\n",
    "\n",
    "        # initialize distance to 'infinity' and cluster to 'none'\n",
    "        distance = np.inf\n",
    "        cluster = None\n",
    "\n",
    "        for j in range(len(centroids)):\n",
    "\n",
    "            centroid = centroids[j]\n",
    "\n",
    "            if abs(centroid - value) < distance:\n",
    "\n",
    "                distance = abs(centroid - value)\n",
    "\n",
    "                clusters[i] = j  \n",
    "\n",
    "    new_centroids = [[] for i in range(k)]\n",
    "\n",
    "    for i in range(len(clusters)):\n",
    "        cluster = clusters[i]\n",
    "        new_centroids[cluster].append(values[i])\n",
    "    \n",
    "    new_centroids = list(map(np.mean, new_centroids))\n",
    "\n",
    "    if set(new_centroids) == set(centroids):\n",
    "        return clusters, centroids\n",
    "    else:\n",
    "        clusters, centroids = k_means(values, k, new_centroids)\n",
    "    \n",
    "    return clusters, centroids\n",
    "\n",
    "def get_wss(values, clusters, centroids):\n",
    "    \n",
    "    se = []\n",
    "\n",
    "    for i in range(len(values)):\n",
    "        se.append((centroids[clusters[i]] - values[i]) ** 2)\n",
    "\n",
    "    wss = sum(se)\n",
    "\n",
    "    return wss\n",
    "\n",
    "def optimize_k(values, ks):\n",
    "    \n",
    "    wsss = {}\n",
    "    \n",
    "    for k in ks:\n",
    "        clusters, centroids = k_means(values, k)\n",
    "        wss = get_wss(values, clusters, centroids)\n",
    "        wsss[k] = wss\n",
    "        \n",
    "    return wsss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing optimize_k() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kss = [3, 5, 10, 50, 100]\n",
    "# wsss = optimize_k(values, kss)\n",
    "# plt.plot(list(wsss.keys()), list(wsss.values()))\n",
    "# plt.title(\"elbow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>vgood</td>\n",
       "      <td>vgood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>high</td>\n",
       "      <td>vgood</td>\n",
       "      <td>vgood</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1728 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     buying  maint  doors persons lug_boot safety  CLASS predictions\n",
       "0     vhigh  vhigh      2       2    small    low  unacc       unacc\n",
       "1     vhigh  vhigh      2       2    small    med  unacc       unacc\n",
       "2     vhigh  vhigh      2       2    small   high  unacc       unacc\n",
       "3     vhigh  vhigh      2       2      med    low  unacc       unacc\n",
       "4     vhigh  vhigh      2       2      med    med  unacc       unacc\n",
       "...     ...    ...    ...     ...      ...    ...    ...         ...\n",
       "1723    low    low  5more    more      med    med   good        good\n",
       "1724    low    low  5more    more      med   high  vgood       vgood\n",
       "1725    low    low  5more    more      big    low  unacc       unacc\n",
       "1726    low    low  5more    more      big    med   good        good\n",
       "1727    low    low  5more    more      big   high  vgood       vgood\n",
       "\n",
       "[1728 rows x 8 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for naive bayes\n",
    "\n",
    "def get_categoric_priors(df):\n",
    "    \n",
    "    # returns dataframe of categorical attributes' prior probabilities\n",
    "    \n",
    "    priors = []\n",
    "    \n",
    "    for column in df.columns[:-1]:\n",
    "        \n",
    "        # create \"n\" column to be able to aggregate attributes\n",
    "        \n",
    "        df2 = df.copy()\n",
    "        df2[\"n\"] = 1\n",
    "        \n",
    "        # get count of classes and count of attribute given class\n",
    "        \n",
    "        attributes = df2.groupby([\"CLASS\", column]).agg({\"n\": \"count\"}).reset_index()\n",
    "        classes = attributes.groupby([\"CLASS\"])[\"n\"].sum().reset_index().rename(columns = {\"n\": \"total\"})\n",
    "        prior = pd.merge(attributes, classes, on = \"CLASS\", how = \"left\")\n",
    "        \n",
    "        # create \"attribute\" column to be able to concat prior dataframes\n",
    "        \n",
    "        prior[\"attribute\"] = column\n",
    "        prior = prior.rename(columns = {column: \"attribute_value\"})\n",
    "        \n",
    "        # get P(attribute|class)\n",
    "        \n",
    "        prior[\"p\"] = prior.n / prior.total\n",
    "        prior = prior[[\"CLASS\", \"attribute\", \"attribute_value\", \"n\", \"total\", \"p\"]]\n",
    "        \n",
    "        priors.append(prior)\n",
    "        \n",
    "    priors = pd.concat(priors)\n",
    "        \n",
    "    return priors\n",
    "\n",
    "# for gnb\n",
    "\n",
    "def get_numeric_statistics(df):\n",
    "    \n",
    "    # returns dataframe of numerical attributes' mean and standard deviation\n",
    "    \n",
    "    numerical_statistics = df.agg([\"mean\", \"std\"]).transpose().reset_index().rename(columns = {\"index\": \"attribute\"})\n",
    "    \n",
    "    return numerical_statistics\n",
    "\n",
    "def gaussian_pdf(x, mean, std):\n",
    "    \n",
    "    # gaussian function used to determine P(X = x|C) \n",
    "    \n",
    "    return (1/(std * sqrt(2 * pi))) * e ** (-1/2 * ((x - mean)/std) ** 2)\n",
    "\n",
    "\n",
    "# class priors\n",
    "\n",
    "def get_class_priors(df):\n",
    "    \n",
    "    # returns the probability of each class occuring\n",
    "    \n",
    "    prior = df.groupby([\"CLASS\"]).size().reset_index().rename(columns = {0: \"n\"})\n",
    "    prior[\"total\"] = sum(prior[\"n\"])\n",
    "    \n",
    "    # get P(class)\n",
    "    \n",
    "    prior[\"p\"] = prior.n / prior.total\n",
    "    \n",
    "    return prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should calculat prior probabilities and likelihoods from the training data and using\n",
    "# them to build a naive Bayes model\n",
    "\n",
    "def train(df):\n",
    "\n",
    "    class train_model:\n",
    "        def __init__(self, class_priors, categoric_priors, numeric_statistics):\n",
    "            \n",
    "            self.class_priors = class_priors\n",
    "            self.categoric_priors = categoric_priors\n",
    "            self.numeric_statistics = numeric_statistics\n",
    "\n",
    "        def gaussian_pdf(self, x, mean, std):\n",
    "            # gaussian function used to determine P(X = x|C) \n",
    "            return (1/(std * sqrt(2 * pi))) * e ** (-1/2 * ((x - mean)/std) ** 2)\n",
    "\n",
    "        def predict(self, df):\n",
    "            \n",
    "            # epsilon smoothing value\n",
    "            epsilon = 1/(df.size + 1)\n",
    "            \n",
    "            predictions = []\n",
    "            \n",
    "            dtypes = df.dtypes.apply(lambda x: x.name).to_dict()\n",
    "            \n",
    "            CLASSES = model.class_priors.CLASS.tolist()\n",
    "            \n",
    "            class_ps = {}\n",
    "            \n",
    "            for row_number, row in df.iterrows():\n",
    "\n",
    "                for CLASS in CLASSES:\n",
    "\n",
    "                    attribute_ps = {}\n",
    "\n",
    "                    for index in row.index[:-1]:\n",
    "\n",
    "                        attribute = index \n",
    "                        attribute_value = row[index]\n",
    "\n",
    "                        if dtypes[attribute] in categoric:\n",
    "\n",
    "                            attribute_p = model.categoric_priors.loc[\n",
    "                                (model.categoric_priors[\"CLASS\"] == CLASS) & \\\n",
    "                                (model.categoric_priors[\"attribute\"] == attribute) & \\\n",
    "                                (model.categoric_priors[\"attribute_value\"] == attribute_value)\n",
    "                            ].p.values[0]\n",
    "                            \n",
    "                            # simple epsilon smoothing\n",
    "                            if (attribute_p == 0):\n",
    "                                attribute_p = epsilon\n",
    "                            \n",
    "                            attribute_ps[attribute] = attribute_p\n",
    "\n",
    "                        elif dtypes[attribute] in numeric:\n",
    "\n",
    "                            mean = model.numeric_statistics.loc[\n",
    "                                model.numeric_statistics.attribute == attribute\n",
    "                            ][\"mean\"].values[0]\n",
    "                            \n",
    "                            std = model.numeric_statistics.loc[\n",
    "                                model.numeric_statistics.attribute == attribute\n",
    "                            ][\"std\"].values[0]\n",
    "\n",
    "                            attribute_p = model.gaussian_pdf(attribute_value, mean, std)\n",
    "                            \n",
    "                            # simple epsilon smoothing\n",
    "                            if (attribute_p == 0):\n",
    "                                attribute_p = epsilon\n",
    "                            \n",
    "                            attribute_ps[attribute] = attribute_p\n",
    "                            \n",
    "                        else:\n",
    "                            attribute_ps[attribute] = epsilon\n",
    "\n",
    "                    class_p = model.class_priors.loc[\n",
    "                        model.class_priors[\"CLASS\"] == CLASS\n",
    "                    ].p.values[0]\n",
    "                    \n",
    "                    class_p = log(class_p)\n",
    "                    \n",
    "                    # for value in attribute_ps.values():\n",
    "                    #     class_p *= value\n",
    "                        \n",
    "                    # logarithmic smoothing\n",
    "        \n",
    "                    for value in attribute_ps.values():\n",
    "                        class_p += log(value)\n",
    "\n",
    "                    class_ps[CLASS] = class_p\n",
    "\n",
    "                prediction = list({k: v for k, v in sorted(class_ps.items(), key=lambda item: item[1], reverse=True)}.keys())[0]\n",
    "\n",
    "                predictions.append(prediction)\n",
    "                                   \n",
    "            return predictions\n",
    "    \n",
    "    ###\n",
    "    \n",
    "    numeric = ['int64', 'float64']\n",
    "    categoric = ['category']\n",
    "    \n",
    "    class_priors = get_class_priors(df)\n",
    "\n",
    "    if len(df.select_dtypes(numeric).columns) > 1:\n",
    "        numeric_statistics = get_numeric_statistics(df.select_dtypes(numeric))\n",
    "    else:\n",
    "        numeric_statistics = None\n",
    "        \n",
    "    if len(df.select_dtypes(categoric).columns) > 1:\n",
    "        categoric_priors = get_categoric_priors(df.select_dtypes(categoric))\n",
    "    else:\n",
    "        categoric_priors = None\n",
    "    \n",
    "    model = train_model(class_priors, categoric_priors, numeric_statistics)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should predict classes for new items in a test dataset (for the purposes of this assignment, you\n",
    "# can re-use the training data as a test set\n",
    "\n",
    "# Multiplying probs, need to take logs of probabilities\n",
    "# Smoothe training probabilities\n",
    "# Change format of the probabilities, and ways of accessing them\n",
    "def predict(df, model):\n",
    "    \n",
    "    predictions = model.predict(df)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         workclass  fnlwgt   education  education-num  \\\n",
       "0       39         State-gov   77516   Bachelors             13   \n",
       "1       50  Self-emp-not-inc   83311   Bachelors             13   \n",
       "2       38           Private  215646     HS-grad              9   \n",
       "3       53           Private  234721        11th              7   \n",
       "4       28           Private  338409   Bachelors             13   \n",
       "...    ...               ...     ...         ...            ...   \n",
       "32556   27           Private  257302  Assoc-acdm             12   \n",
       "32557   40           Private  154374     HS-grad              9   \n",
       "32558   58           Private  151910     HS-grad              9   \n",
       "32559   22           Private  201490     HS-grad              9   \n",
       "32560   52      Self-emp-inc  287927     HS-grad              9   \n",
       "\n",
       "           marital-status         occupation   relationship   race     sex  \\\n",
       "0           Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1      Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2                Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3      Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4      Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "...                   ...                ...            ...    ...     ...   \n",
       "32556  Married-civ-spouse       Tech-support           Wife  White  Female   \n",
       "32557  Married-civ-spouse  Machine-op-inspct        Husband  White    Male   \n",
       "32558             Widowed       Adm-clerical      Unmarried  White  Female   \n",
       "32559       Never-married       Adm-clerical      Own-child  White    Male   \n",
       "32560  Married-civ-spouse    Exec-managerial           Wife  White  Female   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week native-country  CLASS  \n",
       "0              2174             0              40  United-States  <=50K  \n",
       "1                 0             0              13  United-States  <=50K  \n",
       "2                 0             0              40  United-States  <=50K  \n",
       "3                 0             0              40  United-States  <=50K  \n",
       "4                 0             0              40           Cuba  <=50K  \n",
       "...             ...           ...             ...            ...    ...  \n",
       "32556             0             0              38  United-States  <=50K  \n",
       "32557             0             0              40  United-States   >50K  \n",
       "32558             0             0              40  United-States  <=50K  \n",
       "32559             0             0              20  United-States  <=50K  \n",
       "32560         15024             0              40  United-States   >50K  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle, seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folds(df, size): \n",
    "    seed(2020)\n",
    "    seq = list(range(df.shape[0]))\n",
    "    shuffle(seq)\n",
    "    folds = [seq[i::size] for i in range(size)]\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(df, k):\n",
    "    \n",
    "    folds = get_folds(df, k)\n",
    "\n",
    "    metrics_list = []\n",
    "    \n",
    "    for i in range(len(folds)):\n",
    "        \n",
    "        folds2 = folds.copy()\n",
    "\n",
    "        test_index = folds2.pop(i)\n",
    "        train_index = [index for fold in folds2 for index in fold]\n",
    "\n",
    "        test_df = df.iloc[test_index]\n",
    "        train_df = df.iloc[train_index]\n",
    "\n",
    "        model = train(train_df)\n",
    "\n",
    "        predictions = predict(test_df, model)\n",
    "        labels = test_df['CLASS'].tolist()\n",
    "        \n",
    "        metrics = evaluate(labels, predictions)\n",
    "        \n",
    "        print(f\"cross validation fold {i} accuracy: {metrics}\")\n",
    "\n",
    "        metrics_list.append(metrics)\n",
    "    \n",
    "    metrics = np.mean(metrics_list)\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(labels, predictions):\n",
    "    \n",
    "    correct = 0;\n",
    "    incorrect = 0;\n",
    "    \n",
    "    for i in range(0, len(labels)):\n",
    "        if(labels[i] == predictions[i]):\n",
    "            correct += 1\n",
    "        else:\n",
    "            incorrect += 1;\n",
    "\n",
    "    accuracy = correct/(correct + incorrect)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wdbc\n"
     ]
    }
   ],
   "source": [
    "filename = \"wdbc\"\n",
    "\n",
    "print(filename)\n",
    "    \n",
    "# read in data\n",
    "df = read_data(filename)\n",
    "\n",
    "# preprocess data\n",
    "df = preprocess(df, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = discretise(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M']"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(df.iloc[1:10], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLASS</th>\n",
       "      <th>attribute</th>\n",
       "      <th>attribute_value</th>\n",
       "      <th>n</th>\n",
       "      <th>total</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>feat1</td>\n",
       "      <td>21.883111</td>\n",
       "      <td>0</td>\n",
       "      <td>357</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M</td>\n",
       "      <td>feat1</td>\n",
       "      <td>9.707765</td>\n",
       "      <td>0</td>\n",
       "      <td>212</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>feat3</td>\n",
       "      <td>139.917391</td>\n",
       "      <td>0</td>\n",
       "      <td>357</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M</td>\n",
       "      <td>feat3</td>\n",
       "      <td>61.607403</td>\n",
       "      <td>0</td>\n",
       "      <td>212</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>feat4</td>\n",
       "      <td>1904.307692</td>\n",
       "      <td>0</td>\n",
       "      <td>357</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>feat8</td>\n",
       "      <td>0.145514</td>\n",
       "      <td>0</td>\n",
       "      <td>357</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M</td>\n",
       "      <td>feat8</td>\n",
       "      <td>0.011526</td>\n",
       "      <td>0</td>\n",
       "      <td>212</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>feat11</td>\n",
       "      <td>2.710000</td>\n",
       "      <td>0</td>\n",
       "      <td>357</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>feat13</td>\n",
       "      <td>7.984364</td>\n",
       "      <td>0</td>\n",
       "      <td>357</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>feat13</td>\n",
       "      <td>20.315000</td>\n",
       "      <td>0</td>\n",
       "      <td>357</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>feat14</td>\n",
       "      <td>158.266667</td>\n",
       "      <td>0</td>\n",
       "      <td>357</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>feat14</td>\n",
       "      <td>533.900000</td>\n",
       "      <td>0</td>\n",
       "      <td>357</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>M</td>\n",
       "      <td>feat17</td>\n",
       "      <td>0.349900</td>\n",
       "      <td>0</td>\n",
       "      <td>212</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>M</td>\n",
       "      <td>feat20</td>\n",
       "      <td>0.023137</td>\n",
       "      <td>0</td>\n",
       "      <td>212</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>feat21</td>\n",
       "      <td>27.746154</td>\n",
       "      <td>0</td>\n",
       "      <td>357</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M</td>\n",
       "      <td>feat21</td>\n",
       "      <td>10.863394</td>\n",
       "      <td>0</td>\n",
       "      <td>212</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>feat23</td>\n",
       "      <td>152.289412</td>\n",
       "      <td>0</td>\n",
       "      <td>357</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>feat23</td>\n",
       "      <td>195.289286</td>\n",
       "      <td>0</td>\n",
       "      <td>357</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M</td>\n",
       "      <td>feat23</td>\n",
       "      <td>71.921983</td>\n",
       "      <td>0</td>\n",
       "      <td>212</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>feat24</td>\n",
       "      <td>1794.092308</td>\n",
       "      <td>0</td>\n",
       "      <td>357</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>feat24</td>\n",
       "      <td>2838.294118</td>\n",
       "      <td>0</td>\n",
       "      <td>357</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>feat28</td>\n",
       "      <td>0.226979</td>\n",
       "      <td>0</td>\n",
       "      <td>357</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>feat29</td>\n",
       "      <td>0.495411</td>\n",
       "      <td>0</td>\n",
       "      <td>357</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CLASS attribute  attribute_value  n  total    p\n",
       "4     B     feat1        21.883111  0    357  0.0\n",
       "5     M     feat1         9.707765  0    212  0.0\n",
       "4     B     feat3       139.917391  0    357  0.0\n",
       "5     M     feat3        61.607403  0    212  0.0\n",
       "4     B     feat4      1904.307692  0    357  0.0\n",
       "4     B     feat8         0.145514  0    357  0.0\n",
       "5     M     feat8         0.011526  0    212  0.0\n",
       "4     B    feat11         2.710000  0    357  0.0\n",
       "3     B    feat13         7.984364  0    357  0.0\n",
       "4     B    feat13        20.315000  0    357  0.0\n",
       "3     B    feat14       158.266667  0    357  0.0\n",
       "4     B    feat14       533.900000  0    357  0.0\n",
       "9     M    feat17         0.349900  0    212  0.0\n",
       "9     M    feat20         0.023137  0    212  0.0\n",
       "4     B    feat21        27.746154  0    357  0.0\n",
       "5     M    feat21        10.863394  0    212  0.0\n",
       "3     B    feat23       152.289412  0    357  0.0\n",
       "4     B    feat23       195.289286  0    357  0.0\n",
       "5     M    feat23        71.921983  0    212  0.0\n",
       "3     B    feat24      1794.092308  0    357  0.0\n",
       "4     B    feat24      2838.294118  0    357  0.0\n",
       "4     B    feat28         0.226979  0    357  0.0\n",
       "4     B    feat29         0.495411  0    357  0.0"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.categoric_priors.loc[model.categoric_priors.p == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = read_data(\"wdbc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLASS\n",
       "B    357\n",
       "M    212\n",
       "dtype: int64"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.groupby([\"CLASS\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions \n",
    "\n",
    "\n",
    "If you are in a group of 1, you will respond to question (1), and **one** other of your choosing (two responses in total).\n",
    "\n",
    "If you are in a group of 2, you will respond to question (1) and question (2), and **two** others of your choosing (four responses in total). \n",
    "\n",
    "A response to a question should take about 100–250 words, and make reference to the data wherever possible.\n",
    "\n",
    "#### NOTE: you may develope codes or functions in respond to the question, but your formal answer should be added to a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1\n",
    "Try discretising the numeric attributes in these datasets and treating them as discrete variables in the na¨ıve Bayes classifier. You can use a discretisation method of your choice and group the numeric values into any number of levels (but around 3 to 5 levels would probably be a good starting point). Does discretizing the variables improve classification performance, compared to the Gaussian na¨ıve Bayes approach? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretise(df):\n",
    "    \n",
    "    # after preprocess function\n",
    "    \n",
    "    numeric = ['int64', 'float64']\n",
    "    \n",
    "    for column in df.select_dtypes(numeric).columns:\n",
    "        bins, centroids = k_means(df[column].tolist(), 5)\n",
    "        df[column] = [centroids[bin] for bin in bins]\n",
    "        df[column] = df[column].astype(\"category\")\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wdbc\n",
      "cross validation fold 0 accuracy: 0.7105263157894737\n",
      "cross validation fold 1 accuracy: 0.5964912280701754\n",
      "cross validation fold 2 accuracy: 0.631578947368421\n",
      "cross validation fold 3 accuracy: 0.6228070175438597\n",
      "cross validation fold 4 accuracy: 0.5752212389380531\n",
      "cross validation fold 0 accuracy: 0.9649122807017544\n",
      "cross validation fold 1 accuracy: 0.9385964912280702\n",
      "cross validation fold 2 accuracy: 0.9298245614035088\n",
      "cross validation fold 3 accuracy: 0.9035087719298246\n",
      "cross validation fold 4 accuracy: 0.9380530973451328\n",
      "wine\n",
      "cross validation fold 0 accuracy: 0.3888888888888889\n",
      "cross validation fold 1 accuracy: 0.3888888888888889\n",
      "cross validation fold 2 accuracy: 0.4722222222222222\n",
      "cross validation fold 3 accuracy: 0.42857142857142855\n",
      "cross validation fold 4 accuracy: 0.3142857142857143\n",
      "cross validation fold 0 accuracy: 1.0\n",
      "cross validation fold 1 accuracy: 0.9722222222222222\n",
      "cross validation fold 2 accuracy: 0.9722222222222222\n",
      "cross validation fold 3 accuracy: 1.0\n",
      "cross validation fold 4 accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "nominal_files = [\"breast-cancer-wisconsin\", \"mushroom\", \"lymphography\"]\n",
    "numeric_files = [\"wdbc\", \"wine\"]\n",
    "ordinal_files = [\"car\", \"nursery\", \"somerville\"]\n",
    "mixed_files = [\"adult\", \"bank\", \"university\"]\n",
    "\n",
    "metrics_df_list = []\n",
    "\n",
    "for filename in numeric_files:\n",
    "    \n",
    "    print(filename)\n",
    "    \n",
    "    # read in data\n",
    "    df = read_data(filename)\n",
    "\n",
    "    # preprocess data\n",
    "    df = preprocess(df, filename)\n",
    "\n",
    "    # discretise df\n",
    "    df2 = df.copy()\n",
    "    df2 = discretise(df2)\n",
    "\n",
    "    metrics = cross_validation(df, 5)\n",
    "    metrics2 = cross_validation(df2, 5)\n",
    "\n",
    "    metrics_df = pd.DataFrame(data = {\"filename\": [filename], \"accuracy\": [metrics], \"accuracy_discretised\": [metrics2]})\n",
    "    \n",
    "    metrics_df_list.append(metrics_df)\n",
    "    \n",
    "metrics_df = pd.concat(metrics_df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, for the numeric datasets. It seems the naiva bayes performs better than the Gaussian Naive Bayes. This is likely because the numeric attributes violate the assumption that the data is normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2\n",
    "Implement a baseline model (e.g., random or 0R) and compare the performance of the na¨ıve Bayes classifier to this baseline on multiple datasets. Discuss why the baseline performance varies across datasets, and to what extent the na¨ıve Bayes classifier improves on the baseline performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3\n",
    "Since it’s difficult to model the probabilities of ordinal data, ordinal attributes are often treated as either nominal variables or numeric variables. Compare these strategies on the ordinal datasets provided. Deterimine which approach gives higher classification accuracy and discuss why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4\n",
    "Evaluating the model on the same data that we use to train the model is considered to be a major mistake in Machine Learning. Implement a hold–out or cross–validation evaluation strategy (you should implement this yourself and do not simply call existing implementations from `scikit-learn`). How does your estimate of effectiveness change, compared to testing on the training data? Explain why. (The result might surprise you!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5\n",
    "Implement one of the advanced smoothing regimes (add-k, Good-Turing). Does changing the smoothing regime (or indeed, not smoothing at all) affect the effectiveness of the na¨ıve Bayes classifier? Explain why, or why not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6\n",
    "The Gaussian na¨ıve Bayes classifier assumes that numeric attributes come from a Gaussian distribution. Is this assumption always true for the numeric attributes in these datasets? Identify some cases where the Gaussian assumption is violated and describe any evidence (or lack thereof) that this has some effect on the NB classifier’s predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the numeric datasets, performance is much better with Naive Bayes (categorical) compared to GNB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_discretised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wdbc</td>\n",
       "      <td>0.627325</td>\n",
       "      <td>0.934979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wine</td>\n",
       "      <td>0.398571</td>\n",
       "      <td>0.988889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename  accuracy  accuracy_discretised\n",
       "0     wdbc  0.627325              0.934979\n",
       "0     wine  0.398571              0.988889"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "can also plot the variables..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
